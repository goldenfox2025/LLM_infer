#include <cuda_bf16.h>
#include <cuda_runtime.h>
#include <curand_kernel.h>

#include <chrono>
#include <iomanip>
#include <iostream>
#include <stdexcept>
#include <string>
#include <unordered_map>
#include <vector>

#include "qwen3.hpp"

// -------------------------------
// prefill: é¢„å¡«å……æ¥å£
// -------------------------------
template <typename T>
uint32_t *Qwen3Model<T>::prefill(const Tensor<uint32_t> *input, ThreadPool &thread_pool, KVCacheBase *kv_cache,
                                 size_t top_k, float temperature, float top_p, curandState *d_states) {
    KVCache<T> *typed_cache = dynamic_cast<KVCache<T> *>(kv_cache);

    return operators_->sample(prefill_cuda(input, typed_cache), temperature, top_p, top_k, d_states);
}

// -------------------------------
// prefill_cuda: CUDA ç‰ˆæœ¬çš„é¢„å¡«å……å®ç°
// -------------------------------
template <typename T>
Tensor<T> Qwen3Model<T>::prefill_cuda(const Tensor<uint32_t> *input, KVCache<T> *kv_cache) {
    // ç¡®ä¿è¾“å…¥åœ¨ CUDA ä¸Š
    if (input->device() != Device::CUDA) {
        throw std::runtime_error("Input tensor must be on CUDA device");
    }

    // è·å–è¾“å…¥ä¿¡æ¯
    const size_t seq_len = input->sizes()[0];

    // è®¡ç®—èµ·å§‹KVç¼“å­˜ä½ç½®
    size_t offset = 0;
    if (kv_cache) {
        if (kv_cache->device() != Device::CUDA) {
            throw std::runtime_error("KVCache must be on CUDA device");
        }

        offset = kv_cache->size() - seq_len;
    }

    // åˆ›å»ºresidualå’Œhidden_stateså¼ é‡ï¼Œåœ¨prefillé˜¶æ®µè‡ªåŠ¨ä½¿ç”¨prefill buffer
    Tensor<T> residual({seq_len, hidden_size_}, Device::CUDA);
    Tensor<T> hidden_states({seq_len, hidden_size_}, Device::CUDA);

    // TokenåµŒå…¥ (ä»embedding_tableä¸­è·å–tokenåµŒå…¥)
    operators_->gather(&residual, input, &params_.at("token_embeddings.weight"));

    // åˆå§‹åŒ–è®¡ç®—æµåŒæ­¥
    cudaStreamSynchronize(compute_streams_[3]);
    cudaStreamSynchronize(compute_streams_[4]);

    // ä¸»å¾ªç¯ï¼šéå†æ‰€æœ‰Transformerå±‚
    for (size_t i = 0; i < n_layers_; i++) {
        std::string layer_prefix = "layers." + std::to_string(i) + ".";

        // Attention è¾“å…¥å±‚å½’ä¸€åŒ– (RMSNorm)
        auto &attention_norm_weight = params_.at("rms_att_w" + std::to_string(i));
        operators_->rms_norm(&hidden_states, &residual, &attention_norm_weight, rms_norm_eps_);

        // è·å–åç½®é¡¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        const Tensor<T> *q_bias = nullptr;
        const Tensor<T> *k_bias = nullptr;
        const Tensor<T> *v_bias = nullptr;
        const Tensor<T> *o_bias = nullptr;

        try {
            q_bias = &params_.at(layer_prefix + "self_attn.q_proj.bias");
        } catch (const std::out_of_range &) {
        }

        try {
            k_bias = &params_.at(layer_prefix + "self_attn.k_proj.bias");
        } catch (const std::out_of_range &) {
        }

        try {
            v_bias = &params_.at(layer_prefix + "self_attn.v_proj.bias");
        } catch (const std::out_of_range &) {
        }

        try {
            o_bias = &params_.at(layer_prefix + "self_attn.o_proj.bias");
        } catch (const std::out_of_range &) {
        }

        // åˆ›å»ºq/k/vå‘é‡çš„ç¼“å†²åŒº
        Tensor<T> q_buf({seq_len, n_heads_ * head_dim_}, Device::CUDA);
        Tensor<T> k_buf({seq_len, n_kv_heads_ * head_dim_}, Device::CUDA);
        Tensor<T> v_buf({seq_len, n_kv_heads_ * head_dim_}, Device::CUDA);

        // è·å–æƒé‡ï¼ˆè‡ªåŠ¨å¤„ç†é‡åŒ–ä¸éé‡åŒ–æƒ…å†µï¼‰
        auto q_weight = get_weight("wq" + std::to_string(i));
        auto k_weight = get_weight("wk" + std::to_string(i));
        auto v_weight = get_weight("wv" + std::to_string(i));

        // debugPrintTensor(hidden_states, "hidden_states");
        // debugPrintTensor(*q_weight.tensor(), "q_weight");
        // ä½¿ç”¨ä¸åŒçš„è®¡ç®—æµå¹¶è¡Œå¤„ç†Q/K/VçŸ©é˜µä¹˜æ³•
        operators_->matmul(&q_buf, &hidden_states, q_weight, q_bias, compute_streams_[0]);
        operators_->matmul(&k_buf, &hidden_states, k_weight, k_bias, compute_streams_[1]);
        operators_->matmul(&v_buf, &hidden_states, v_weight, v_bias, compute_streams_[2]);

        // ç­‰å¾…Q/K/Vè®¡ç®—å®Œæˆ
        cudaStreamSynchronize(compute_streams_[0]);
        cudaStreamSynchronize(compute_streams_[1]);
        cudaStreamSynchronize(compute_streams_[2]);

        // Qwen3ç‰¹æœ‰: Q/Kå½’ä¸€åŒ–
        auto &q_norm_weight = params_.at("q_norm" + std::to_string(i));
        auto &k_norm_weight = params_.at("k_norm" + std::to_string(i));

        // å°†q_bufå’Œk_bufé‡å¡‘ä¸º3Då¼ é‡è§†å›¾
        Tensor<T> q_buf_view = q_buf.view({seq_len, n_heads_, head_dim_});
        Tensor<T> k_buf_view = k_buf.view({seq_len, n_kv_heads_, head_dim_});

        // å¯¹æ•´ä¸ªq_buf_viewå’Œk_buf_viewæ‰§è¡ŒRMSå½’ä¸€åŒ–
        // RMSå½’ä¸€åŒ–å®ç°ä¼šè‡ªåŠ¨å¤„ç†æœ€åä¸€ç»´ï¼ˆhead_dim_ï¼‰
        operators_->rms_norm(&q_buf_view, &q_buf_view, &q_norm_weight, rms_norm_eps_);
        operators_->rms_norm(&k_buf_view, &k_buf_view, &k_norm_weight, rms_norm_eps_);

        // åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç  (RoPE)ï¼Œè®¡ç®—æ³¨æ„åŠ›ï¼Œå¹¶æ›´æ–°KVç¼“å­˜
        // ä½¿ç”¨ n_heads_ * head_dim_ è€Œä¸æ˜¯ hidden_size_ æ¥åˆ›å»ºæ³¨æ„åŠ›è¾“å‡ºå¼ é‡
        // è¿™æ ·å¯ä»¥åŒæ—¶æ”¯æŒ 0.6B å’Œ 1.7B æ¨¡å‹
        Tensor<T> attn_output({seq_len, n_heads_ * head_dim_}, Device::CUDA);

        // åº”ç”¨RoPEï¼ˆæ—‹è½¬ä½ç½®ç¼–ç ï¼‰
        operators_->rope(&q_buf_view, offset, rope_theta_);
        operators_->rope(&k_buf_view, offset, rope_theta_);

        // å­˜å‚¨K, Våˆ°ç¼“å­˜
        Tensor<T> v_buf_view = v_buf.view({seq_len, n_kv_heads_, head_dim_});
        for (size_t j = 0; j < seq_len; j++) {
            // è·å–ç¼“å­˜ä¸­çš„ä½ç½®
            Tensor<T> &k_cache_slice = kv_cache->k_cache(i, offset + j);
            Tensor<T> &v_cache_slice = kv_cache->v_cache(i, offset + j);

            // ä»å½“å‰k_buf_viewå’Œv_buf_viewä¸­æ‹·è´åˆ°ç¼“å­˜
            size_t head_size = n_kv_heads_ * head_dim_;
            cudaMemcpy(k_cache_slice.data_ptr(), k_buf_view.data_ptr() + j * head_size, head_size * sizeof(T),
                       cudaMemcpyDeviceToDevice);
            cudaMemcpy(v_cache_slice.data_ptr(), v_buf_view.data_ptr() + j * head_size, head_size * sizeof(T),
                       cudaMemcpyDeviceToDevice);
        }

        // ä»ç¼“å­˜è·å–å®Œæ•´çš„Kå’ŒVåºåˆ—
        auto [k_cache_tensor, v_cache_tensor] = kv_cache->get_contiguous_tensor(i);
        size_t total_seq_len = offset + seq_len;

        Tensor<T> k_cache_view = k_cache_tensor.view({total_seq_len, n_kv_heads_, head_dim_});
        Tensor<T> v_cache_view = v_cache_tensor.view({total_seq_len, n_kv_heads_, head_dim_});

        // // ========== å¯¹æ¯”ä¸¤ç§æ³¨æ„åŠ›è®¡ç®—æ–¹æ³• ==========

        // // åˆ›å»ºä¸¤ä¸ªç‹¬ç«‹çš„è¾“å‡ºå¼ é‡
        Tensor<T> attn_output_flash({seq_len, n_heads_ * head_dim_}, Device::CUDA);
        // Tensor<T> attn_output_separate({seq_len, n_heads_ * head_dim_}, Device::CUDA);

        // std::cout << "Layer " << i << ": å¼€å§‹å¯¹æ¯”ä¸¤ç§æ³¨æ„åŠ›è®¡ç®—æ–¹æ³•..." << std::endl;

        // // æ–¹æ³•1: Flash Attention (æ ‡è®°ä¸ºé”™è¯¯çš„)
        // {
        Tensor<T> att_out_view_flash = attn_output_flash.view({seq_len, n_heads_, head_dim_});
        operators_->flash_attention_prefill(q_buf_view, k_cache_view, v_cache_view, att_out_view_flash, n_heads_,
                                            n_kv_heads_, head_dim_, seq_len, total_seq_len, offset);
        // }

        // // æ–¹æ³•2: åˆ†å¼€çš„è®¡ç®—è·¯å¾„ (æ ‡è®°ä¸ºæ­£ç¡®çš„)
        // {
        //     Tensor<T> att_scores({seq_len, n_heads_, total_seq_len}, Device::CUDA);
        //     operators_->compute_attention_scores_prefill(q_buf_view, k_cache_view, att_scores, head_dim_);

        //     // Softmaxå¤„ç†æ³¨æ„åŠ›åˆ†æ•°ï¼ˆprefillç‰ˆæœ¬éœ€è¦è®¾ç½®mask=trueï¼‰
        //     operators_->softmax(&att_scores, &att_scores, /*dim=*/2, true, offset);

        //     // è®¡ç®—æ³¨æ„åŠ›è¾“å‡ºï¼ˆprefillç‰ˆæœ¬ï¼‰
        //     Tensor<T> att_out_view_separate = attn_output_separate.view({seq_len, n_heads_, head_dim_});
        //     operators_->compute_attention_output_prefill(att_scores, v_cache_view, att_out_view_separate, n_heads_,
        //                                                  head_dim_, total_seq_len, n_kv_heads_);
        // }

        // // åŒæ­¥è®¡ç®—æµç¡®ä¿ä¸¤ç§è®¡ç®—éƒ½å®Œæˆ
        // cudaDeviceSynchronize();

        // // å¯¹æ¯”ä¸¤ä¸ªç»“æœ
        // {
        //     const size_t total_elements = seq_len * n_heads_ * head_dim_;
        //     const float tolerance = 1e-1f;  // è¯¯å·®å®¹å¿åº¦

        //     // å°†æ•°æ®å¤åˆ¶åˆ°CPUè¿›è¡Œæ¯”è¾ƒ
        //     std::vector<float> flash_data(total_elements);
        //     std::vector<float> separate_data(total_elements);

        //     // å¤åˆ¶æ•°æ®åˆ°CPUå¹¶è½¬æ¢ä¸ºfloatè¿›è¡Œæ¯”è¾ƒ
        //     if constexpr (std::is_same_v<T, __nv_bfloat16>) {
        //         // ä¸ºbfloat16æ•°æ®åˆ›å»ºCPUç¼“å†²åŒº
        //         std::vector<__nv_bfloat16> flash_bf16(total_elements);
        //         std::vector<__nv_bfloat16> separate_bf16(total_elements);

        //         // å¤åˆ¶æ•°æ®åˆ°CPU
        //         cudaMemcpy(flash_bf16.data(), attn_output_flash.data_ptr(), total_elements * sizeof(__nv_bfloat16),
        //                    cudaMemcpyDeviceToHost);
        //         cudaMemcpy(separate_bf16.data(), attn_output_separate.data_ptr(),
        //                    total_elements * sizeof(__nv_bfloat16), cudaMemcpyDeviceToHost);

        //         // è½¬æ¢ä¸ºfloat
        //         for (size_t idx = 0; idx < total_elements; ++idx) {
        //             flash_data[idx] = static_cast<float>(flash_bf16[idx]);
        //             separate_data[idx] = static_cast<float>(separate_bf16[idx]);
        //         }
        //     } else if constexpr (std::is_same_v<T, float>) {
        //         // ç›´æ¥å¤åˆ¶floatæ•°æ®
        //         cudaMemcpy(flash_data.data(), attn_output_flash.data_ptr(), total_elements * sizeof(float),
        //                    cudaMemcpyDeviceToHost);
        //         cudaMemcpy(separate_data.data(), attn_output_separate.data_ptr(), total_elements * sizeof(float),
        //                    cudaMemcpyDeviceToHost);
        //     } else {
        //         // å¯¹äºå…¶ä»–æ•°æ®ç±»å‹ï¼Œå…ˆå¤åˆ¶ç„¶åè½¬æ¢
        //         std::vector<T> flash_raw(total_elements);
        //         std::vector<T> separate_raw(total_elements);

        //         cudaMemcpy(flash_raw.data(), attn_output_flash.data_ptr(), total_elements * sizeof(T),
        //                    cudaMemcpyDeviceToHost);
        //         cudaMemcpy(separate_raw.data(), attn_output_separate.data_ptr(), total_elements * sizeof(T),
        //                    cudaMemcpyDeviceToHost);

        //         for (size_t idx = 0; idx < total_elements; ++idx) {
        //             flash_data[idx] = static_cast<float>(flash_raw[idx]);
        //             separate_data[idx] = static_cast<float>(separate_raw[idx]);
        //         }
        //     }

        //     // æ¯”è¾ƒç»“æœ
        //     float max_diff = 0.01f;
        //     size_t max_diff_idx = 0;
        //     size_t first_error_idx = total_elements;  // åˆå§‹åŒ–ä¸ºæœ€å¤§å€¼ï¼Œè¡¨ç¤ºæ²¡æœ‰é”™è¯¯

        //     for (size_t idx = 0; idx < total_elements; ++idx) {
        //         float diff = std::abs(flash_data[idx] - separate_data[idx]);

        //         if (diff > max_diff) {
        //             max_diff = diff;
        //             max_diff_idx = idx;
        //         }

        //         if (diff > tolerance && first_error_idx == total_elements) {
        //             first_error_idx = idx;
        //         }
        //     }

        //     std::cout << "Layer " << i << " ç»“æœå¯¹æ¯”:" << std::endl;
        //     std::cout << "  æœ€å¤§å·®è·: " << std::scientific << std::setprecision(6) << max_diff
        //               << " (ä½ç½®: " << max_diff_idx << ")" << std::endl;

        //     if (max_diff > tolerance) {
        //         std::cout << "  æœ€å¤§å·®è·è¯¦æƒ… - Flash: " << std::fixed << std::setprecision(6)
        //                   << flash_data[max_diff_idx] << ", Separate: " << separate_data[max_diff_idx] << std::endl;
        //     }

        //     if (first_error_idx < total_elements) {
        //         std::cout << "  âŒ å‘ç°è¯¯å·®è¶…å‡ºå®¹å¿åº¦! (å®¹å¿åº¦: " << std::scientific << tolerance << ")" <<
        //         std::endl; std::cout << "  ç¬¬ä¸€ä¸ªé”™è¯¯ä½ç½®: " << first_error_idx << " (å·®è·: " << std::scientific
        //                   << std::setprecision(6)
        //                   << std::abs(flash_data[first_error_idx] - separate_data[first_error_idx]) << ")" <<
        //                   std::endl;
        //         std::cout << "  ç¬¬ä¸€ä¸ªé”™è¯¯åŠå…¶å5ä¸ªå€¼:" << std::endl;

        //         for (size_t j = 0; j < 6 && (first_error_idx + j) < total_elements; ++j) {
        //             size_t idx = first_error_idx + j;
        //             float diff = std::abs(flash_data[idx] - separate_data[idx]);
        //             std::cout << "    [" << std::setw(6) << idx << "] Flash: " << std::fixed << std::setprecision(8)
        //                       << flash_data[idx] << ", Separate: " << std::setprecision(8) << separate_data[idx]
        //                       << ", å·®è·: " << std::scientific << std::setprecision(6) << diff;
        //             if (diff > tolerance) {
        //                 std::cout << " âš ï¸ è¶…å‡ºå®¹å¿åº¦";
        //             }
        //             std::cout << std::endl;
        //         }

        //         // é¢å¤–ç»Ÿè®¡ä¿¡æ¯
        //         size_t error_count = 0;
        //         for (size_t idx = 0; idx < total_elements; ++idx) {
        //             if (std::abs(flash_data[idx] - separate_data[idx]) > tolerance) {
        //                 error_count++;
        //             }
        //         }
        //         std::cout << "  ğŸ“Š æ€»è®¡: " << error_count << "/" << total_elements << " ä¸ªå…ƒç´ è¶…å‡ºå®¹å¿åº¦ ("
        //                   << std::fixed << std::setprecision(2) << (100.0 * error_count / total_elements) << "%)"
        //                   << std::endl;
        //     } else {
        //         std::cout << "  âœ… æ‰€æœ‰å€¼éƒ½åœ¨å®¹å¿åº¦èŒƒå›´å†… (å®¹å¿åº¦: " << std::scientific << tolerance << ")"
        //                   << std::endl;
        //     }
        //     std::cout << std::endl;
        // }

        // ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•çš„ç»“æœç»§ç»­åç»­è®¡ç®—
        attn_output = attn_output_flash;
        attn_output = attn_output.view({seq_len, n_heads_ * head_dim_});
        // æ³¨æ„åŠ›è¾“å‡ºæŠ•å½±
        Tensor<T> attn_proj({seq_len, hidden_size_}, Device::CUDA);

        // è·å–æƒé‡ï¼ˆè‡ªåŠ¨å¤„ç†é‡åŒ–ä¸éé‡åŒ–æƒ…å†µï¼‰
        auto o_weight = get_weight("wo" + std::to_string(i));

        // æ‰§è¡ŒçŸ©é˜µä¹˜æ³•
        operators_->matmul(&attn_proj, &attn_output, o_weight, o_bias);

        // æ®‹å·®è¿æ¥
        operators_->add(&residual, &residual, &attn_proj);

        // FFN è¾“å…¥å±‚å½’ä¸€åŒ– (RMSNorm)
        auto &ffn_norm_weight = params_.at("rms_ffn_w" + std::to_string(i));
        operators_->rms_norm(&hidden_states, &residual, &ffn_norm_weight, rms_norm_eps_);

        // MLP (Feed-Forward Network)
        const Tensor<T> *gate_bias = nullptr;
        const Tensor<T> *up_bias = nullptr;
        const Tensor<T> *down_bias = nullptr;

        try {
            gate_bias = &params_.at(layer_prefix + "mlp.gate_proj.bias");
        } catch (const std::out_of_range &) {
        }

        try {
            up_bias = &params_.at(layer_prefix + "mlp.up_proj.bias");
        } catch (const std::out_of_range &) {
        }

        try {
            down_bias = &params_.at(layer_prefix + "mlp.down_proj.bias");
        } catch (const std::out_of_range &) {
        }

        // è®¡ç®—Gateå’ŒUpæŠ•å½±
        Tensor<T> gate_buf({seq_len, intermediate_size_}, Device::CUDA);
        Tensor<T> up_buf({seq_len, intermediate_size_}, Device::CUDA);

        // è·å–æƒé‡ï¼ˆè‡ªåŠ¨å¤„ç†é‡åŒ–ä¸éé‡åŒ–æƒ…å†µï¼‰
        auto gate_weight = get_weight("w_gate" + std::to_string(i));
        auto up_weight = get_weight("w_up" + std::to_string(i));

        // æ‰§è¡ŒçŸ©é˜µä¹˜æ³•
        operators_->matmul(&gate_buf, &hidden_states, gate_weight, gate_bias);
        operators_->matmul(&up_buf, &hidden_states, up_weight, up_bias);

        // åº”ç”¨SiLUæ¿€æ´»å‡½æ•°åˆ°gate_bufå¹¶ä¸up_bufç›¸ä¹˜
        operators_->silu(&gate_buf, &gate_buf);               // SiLUæ¿€æ´»
        operators_->multiply(&gate_buf, &gate_buf, &up_buf);  // é€å…ƒç´ ç›¸ä¹˜

        // DownæŠ•å½±
        Tensor<T> ffn_out({seq_len, hidden_size_}, Device::CUDA);

        // è·å–æƒé‡ï¼ˆè‡ªåŠ¨å¤„ç†é‡åŒ–ä¸éé‡åŒ–æƒ…å†µï¼‰
        auto down_weight = get_weight("w_down" + std::to_string(i));

        // æ‰§è¡ŒçŸ©é˜µä¹˜æ³•
        operators_->matmul(&ffn_out, &gate_buf, down_weight, down_bias);

        // æ®‹å·®è¿æ¥
        operators_->add(&residual, &residual, &ffn_out);
    }

    // æœ€ç»ˆçš„LayerNorm (RMSNorm)
    auto &norm_weight = params_.at("rms_out_w");
    Tensor<T> final_h({seq_len, hidden_size_}, Device::CUDA);
    operators_->rms_norm(&final_h, &residual, &norm_weight, rms_norm_eps_);

    // LM headæŠ•å½±åˆ°è¯æ±‡è¡¨å¤§å°
    auto lm_head_weight = get_weight("lm_head");
    const Tensor<T> *lm_head_bias = nullptr;

    Tensor<T> logits({seq_len, vocab_size_}, Device::CUDA);
    // ä½¿ç”¨operators_->matmul
    operators_->matmul(&logits, &final_h, lm_head_weight, lm_head_bias);

    // è¿”å›logits
    return logits;
}

// æ˜¾å¼å®ä¾‹åŒ–æ¨¡æ¿å‡½æ•°
template uint32_t *Qwen3Model<__nv_bfloat16>::prefill(const Tensor<uint32_t> *input, ThreadPool &thread_pool,
                                                      KVCacheBase *kv_cache, size_t top_k, float temperature,
                                                      float top_p, curandState *d_states);

template Tensor<__nv_bfloat16> Qwen3Model<__nv_bfloat16>::prefill_cuda(const Tensor<uint32_t> *input,
                                                                       KVCache<__nv_bfloat16> *kv_cache);
